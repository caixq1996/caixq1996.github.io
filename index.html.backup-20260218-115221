<!doctype html><html lang=zh-CN><head><meta name=generator content="Hugo 0.146.0"><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Xin-Qiang Cai | RIKEN AIP</title>
<meta name=description content="Xin-Qiang Cai ‚Äî Reinforcement Learning, Reward Modeling, Weak Supervision. Postdoctoral Researcher at RIKEN AIP."><meta name=theme-color content="#f8f9fa" media="(prefers-color-scheme: light)"><meta name=theme-color content="#0b1a20" media="(prefers-color-scheme: dark)"><link rel=icon href=./icons/favicon.svg type=image/svg+xml><link rel=icon href=./icons/favicon-32x32.png sizes=32x32><link rel=icon href=./icons/favicon.ico sizes="16x16 32x32 48x48"><link rel=apple-touch-icon href=./icons/android-chrome-192x192.png sizes=192x192><link rel=mask-icon href=./icons/favicon.svg color=#0a9396><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&family=Outfit:wght@500;700&display=swap" rel=stylesheet><style>:root{color-scheme:light dark;--primary:#005f73;--primary-hover:#0a9396;--accent:#0a9396;--title:#101820;--body:#374151;--bg:#f8fafc;--card-bg:rgba(255, 255, 255, 0.65);--glass-border:rgba(255, 255, 255, 0.4);--shadow:0 10px 40px -10px rgba(0, 0, 0, 0.08);--radius:20px;--maxw:1100px;--header-h:70px;--page-bg:248, 250, 252;--canvas-bg-rgb:245, 247, 250;--primary-rgb:0, 95, 115;--accent-rgb:10, 147, 150;--ink-rgb:16, 24, 32}@media(prefers-color-scheme:dark){:root:not([data-theme]){--title:#f1f5f9;--body:#cbd5e1;--card-bg:rgba(15, 23, 42, 0.6);--glass-border:rgba(255, 255, 255, 0.08);--shadow:0 10px 40px -10px rgba(0, 0, 0, 0.5);--page-bg:15, 23, 42;--canvas-bg-rgb:15, 23, 42;--ink-rgb:226, 232, 240}:root:not([data-theme]) .veil{background:radial-gradient(circle at 15% 15%,rgba(10,147,150,.15),transparent 50%),radial-gradient(circle at 85% 85%,rgba(0,95,115,.15),transparent 50%)}}:root[data-theme=dark]{--title:#f1f5f9;--body:#cbd5e1;--card-bg:rgba(15, 23, 42, 0.6);--glass-border:rgba(255, 255, 255, 0.08);--shadow:0 10px 40px -10px rgba(0, 0, 0, 0.5);--page-bg:15, 23, 42;--canvas-bg-rgb:15, 23, 42;--ink-rgb:226, 232, 240}html{scroll-behavior:smooth;background:rgb(var(--page-bg))}body{font-family:inter,system-ui,-apple-system,sans-serif;line-height:1.7;margin:0;color:var(--body);background:0 0;-webkit-font-smoothing:antialiased}h1,h2,h3,h4,.button{font-family:outfit,sans-serif}a{color:var(--primary);text-decoration:none;transition:color .2s;font-weight:500}a:hover{color:var(--accent)}main{padding:1.5rem 1rem;max-width:var(--maxw);margin:0 auto}header{padding:.1rem 1rem 1.5rem;text-align:center;background:radial-gradient(circle at 50% 0%,rgba(10,147,150,.15),transparent 70%);margin-bottom:0}header h1{font-size:clamp(2rem,5vw,3.2rem);margin:0 0 .5rem;color:var(--title);background:linear-gradient(135deg,var(--title) 30%,var(--primary));-webkit-background-clip:text;background-clip:text;-webkit-text-fill-color:transparent;letter-spacing:-.02em}header .tagline{font-size:clamp(1rem,2vw,1.2rem);color:var(--body);opacity:.85;max-width:600px;margin:0 auto}.nav-wrap{position:sticky;top:1rem;z-index:999;display:flex;justify-content:center;padding:0 1rem}nav.nav-buttons{display:flex;gap:6px;flex-wrap:wrap;justify-content:center;padding:8px 10px;background:rgba(255,255,255,.75);backdrop-filter:blur(16px);-webkit-backdrop-filter:blur(16px);border:1px solid var(--glass-border);border-radius:99px;box-shadow:0 8px 32px rgba(0,0,0,8%)}@media(prefers-color-scheme:dark){nav.nav-buttons{background:rgba(15,23,42,.65)}}:root[data-theme=dark] nav.nav-buttons{background:rgba(15,23,42,.65)}.nav-buttons a.button{padding:8px 16px;border-radius:20px;color:var(--body);font-weight:500;font-size:.95rem;transition:all .3s cubic-bezier(.25,1,.5,1)}.nav-buttons a.button:hover,.nav-buttons a.button.active{background:var(--primary);color:#fff;transform:translateY(-1px);box-shadow:0 4px 12px rgba(0,95,115,.3)}.theme-toggle{background:0 0;border:none;cursor:pointer;padding:8px 12px;font-size:1.1rem;transition:transform .3s;border-radius:50%}.theme-toggle:hover{transform:rotate(15deg)scale(1.1);background:rgba(128,128,128,.1)}.grid{display:grid;grid-template-columns:320px 1fr;gap:24px;align-items:stretch;margin-bottom:24px}.grid .section,.grid .card{height:auto!important;margin-bottom:0}@media(max-width:850px){.grid{grid-template-columns:1fr;gap:24px}.nav-buttons a.button{white-space:nowrap;font-size:.85rem;padding:8px 14px}}.card,.section{background:var(--card-bg);backdrop-filter:blur(20px);-webkit-backdrop-filter:blur(20px);border:1px solid var(--glass-border);border-radius:var(--radius);box-shadow:var(--shadow);transition:transform .3s ease,box-shadow .3s ease;height:100%}.section{padding:32px;margin-bottom:24px;height:auto}.grid .section{height:auto;margin-bottom:0}@media(min-width:851px){.card:hover,.section:hover{transform:translateY(-4px);box-shadow:0 12px 40px rgba(0,0,0,.12)}}.profile{padding:30px;text-align:center;position:sticky;top:100px}.profile img{width:min(260px,100%);height:auto;object-fit:contain;border-radius:12px;box-shadow:0 8px 24px rgba(0,0,0,.15);margin-bottom:20px;border:4px solid rgba(255,255,255,.8)}.profile h2{font-size:2rem;margin:10px 0 5px;color:var(--title);font-weight:700}.profile p{margin:6px 0;font-size:.95rem;opacity:.9}.section h2{border-left:5px solid var(--accent);padding-left:15px;margin-bottom:25px;font-size:1.6rem;color:var(--title);border-bottom:none}.section ul{padding-left:1rem}.section li{margin-bottom:.6rem;position:relative}#news p{padding-bottom:12px;border-bottom:1px solid rgba(0,0,0,5%);margin-bottom:12px}#news p:last-child{border-bottom:none;margin-bottom:0}#works p{position:relative;padding:16px;margin:0 0 16px;background:rgba(255,255,255,.4);border-radius:12px;border:1px solid transparent;transition:all .2s;border-left:4px solid transparent}#works p:hover{background:rgba(255,255,255,.8);border-color:var(--glass-border);border-left-color:var(--accent);box-shadow:0 4px 12px rgba(0,0,0,5%)}@media(prefers-color-scheme:dark){:root:not([data-theme=light]) #works p{background:rgba(0,0,0,.2);border:1px solid rgba(255,255,255,5%);border-left:4px solid transparent}:root:not([data-theme=light]) #works p:hover{background:rgba(0,0,0,.4);border-color:rgba(255,255,255,.1);border-left-color:var(--accent)}}:root[data-theme=dark] #works p{background:rgba(0,0,0,.2);border:1px solid rgba(255,255,255,5%);border-left:4px solid transparent}:root[data-theme=dark] #works p:hover{background:rgba(0,0,0,.4);border-color:rgba(255,255,255,.1);border-left-color:var(--accent)}footer{margin-top:4rem;padding:2rem;text-align:center;font-size:.9rem;opacity:.7;background:0 0}#interactive-bg{position:fixed;inset:0;z-index:-2}.veil{position:fixed;inset:0;z-index:-1;pointer-events:none;background:radial-gradient(circle at 50% 50%,rgba(255,255,255,.4),transparent 80%)}@media(max-width:600px){.profile img{width:100%;max-width:260px;height:auto}.section{padding:20px}header h1{font-size:1.8rem}}</style></head><body><canvas id=interactive-bg aria-hidden=true></canvas><div class=veil aria-hidden=true></div><header><h1>Xin-Qiang Cai @ RIKEN-AIP, Tokyo, Japan</h1><p class=tagline>Reward Modeling ‚Ä¢ Reinforcement Learning & Imitation Learning ‚Ä¢ Weak Supervision</p></header><div class=nav-wrap><nav class=nav-buttons aria-label="Section Navigation"><a class=button href=#biography data-target=biography>Biography</a>
<a class=button href=#news data-target=news>News</a>
<a class=button href=#talks data-target=talks>Talks</a>
<a class=button href=#works data-target=works>Works</a>
<a class=button href=#services data-target=services>Services</a>
<a class=button href=#awards data-target=awards>Awards & Honors</a>
<a class=button href=#correspondence data-target=correspondence>Correspondence</a>
<button id=theme-toggle class=theme-toggle aria-label="Toggle dark mode" title="Toggle dark mode">üåô</button></nav></div><main><div class=grid><section class="profile card" aria-labelledby=name-cn><img src=./images/caixq.JPG alt="Xin-Qiang Cai portrait"><div class=profile-info><h2 id=name-cn>Ëî° Ê¨£ Âº∫</h2><p><strong>Xin-Qiang Cai</strong></p><p>Postdoctoral Researcher</p><p><a href=https://aip.riken.jp/labs/generic_tech/imperfect_inf_learn/>Imperfect Information Learning
Team</a></p><p><a href=https://aip.riken.jp/>RIKEN Center for Advanced Intelligence Project</a></p><p>[ <a href="https://scholar.google.com/citations?hl=en&amp;user=rtMUMooAAAAJ&amp;view_op=list_works">Google
Scholar</a>, <a href=https://dblp.org/pid/248/8034.html>dblp</a> ]</p><p><b>Email</b>: xinqiang.cai [at] riken.jp</p><p>(alternative: jkrsndivide [at] gmail.com)</p></div></section><section id=biography class=section aria-labelledby=bio-title><h2 id=bio-title>Biography</h2><p>Currently I am a postdoctoral researcher in the Imperfect Information Learning Team at <a href=https://www.riken.jp/en/research/labs/aip/ target=_blank>RIKEN Center for Advanced Intelligence
Project (AIP)</a>, led by professor <a href=https://www.ms.k.u-tokyo.ac.jp/sugi/ target=_blank>Masashi
Sugiyama</a>.</p><p>I got my Ph.D. degree in <a href=https://www.k.u-tokyo.ac.jp/complex/index_e.html>Department of Complexity
Science and Engineering</a> in September 2024 from <a href=https://www.u-tokyo.ac.jp/en/ target=_blank>The University of Tokyo</a> as a member of <a href=http://www.ms.k.u-tokyo.ac.jp/ target=_blank>Sugiyama-Yokoya-Ishida Lab</a>, supervised by professor <a href=https://www.ms.k.u-tokyo.ac.jp/sugi/ target=_blank>Masashi Sugiyama</a>. Meanwhile, I worked as a
research assistant on <a href=https://beyondai.jp/ target=_blank>Beyond AI Institution</a>.</p><p>I got my M.Eng. degree in <a href=https://www.nju.edu.cn/en/7f/6b/c7136a163691/page.psp target=_blank>Computer Science and Technology</a> in June 2021 from <a href=http://www.nju.edu.cn/ target=_blank>Nanjing University</a> as a member of <a href=http://www.lamda.nju.edu.cn/ target=_blank>LAMDA</a> Group, supervised by professor <a href=https://cs.nju.edu.cn/zhouzh/ target=_blank>Zhi-Hua Zhou</a> and professor <a href=http://www.lamda.nju.edu.cn/jiangy/ target=_blank>Yuan Jiang</a>.</p><p>I got my B.Eng. degree in <a href=http://hangkong.nwpu.edu.cn// target=_blank>Aircraft Design and
Engineering</a> in June 2018 from <a href=https://www.nwpu.edu.cn/ target=_blank>Northwestern
Polytechnical University</a>. In the same year, I was admitted to study for a M.Sc degree in <a href=http://www.nju.edu.cn/ target=_blank>Nanjing University</a> without entrance examination.</p><h3>Research Interests</h3><ul><li>Reward Modeling in RL and RLHF</li><li>Reinforcement Learning & Imitation Learning</li><li>Learning with Weak Supervision</li></ul></section></div><section id=news class=section><h2>News</h2><p>2026. 02: üìë Our paper "VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via Confidence-Guided Variance
Reduction" is on <a href=https://arxiv.org/abs/2602.12579>arXiv</a>.</p><p>2026. 01: üìë Our paper "Positive-Unlabeled Reinforcement Learning Distillation for On-Premise Small Models" is
on <a href=https://arxiv.org/abs/2601.20687>arXiv</a>.</p><p>2025. 10: üìë Our paper "Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label Perspective" is
on <a href=https://arxiv.org/abs/2510.15007>arXiv</a>.</p><p>2025. 10: üìë Our paper "Reinforcement Learning with Verifiable yet Noisy Rewards under Imperfect Verifiers" is
on <a href=https://arxiv.org/abs/2510.00915>arXiv</a>.</p><p>2025. 05: üåê I will attend the workshop between the University of Melbourne and RIKEN-AIP in Melbourne on July
3‚Äì4.</p><p>2025. 05: üåê I will attend the workshop between the University of Sydney and RIKEN-AIP in Sydney on July 7‚Äì8.</p><p>2025. 05: üéâ Our paper ‚ÄúLeveraging Domain-Unlabeled Data in Offline Reinforcement Learning across Two Domains‚Äù
is accepted by RLC 2025.</p><p>2025. 03: üìë Our recent work "UC-MOA: Utility-Conditioned Multi-Objective Alignment for Distributional
Pareto-Optimality" is on <a href=https://arxiv.org/pdf/2503.10669>arXiv</a>.</p><p>2025. 02: üè´ I will visit UAlbany on March 29‚Äì30.</p><p>2025. 02: üí¨ I will have a talk at Mila ‚ÄúReward Modeling in Reinforcement and Imitation Learning: Overcoming
Challenges of Dimensionality, Imperfection, and Uncertainty‚Äù in Montreal on March 28.</p></section><section id=talks class=section><h2>Invited Talks</h2><p>2025/3/28. <b>Reward Modeling in Reinforcement and Imitation Learning: Overcoming Challenges of Dimensionality,
Imperfection, and Uncertainty</b>. Mila.</p><p>2025/3/18. <b>Reward Modeling in Reinforcement and Imitation Learning: Overcoming Challenges of Dimensionality,
Imperfection, and Uncertainty</b>. UCLA.</p><p>2023/6/7. <b>Seeing Differently, Acting Similarly: Heterogeneously Observable Imitation Learning</b>. AI TIME.</p><p>2022/1/11. <b>Imitation Learning from Pixel-Level Demonstrations by HashReward</b>. RLChina.</p></section><section id=works class=section><h2>Preprints (* denotes equal contributions)</h2><p><b>Xin-Qiang Cai</b>, Masashi Sugiyama. VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via
Confidence-Guided Variance Reduction. In: arXiv. [<a href=https://arxiv.org/pdf/2602.12579>arXiv</a>]</p><p>Zhiqiang Kou*, Junyang Chen*, <b>Xin-Qiang Cai</b>, Xiaobo Xia, Ming-Kun Xie, Dong-Dong Wu, Biao Liu, Yuheng
Jia,
Xin Geng, Masashi Sugiyama, Tat-Seng Chua. Positive-Unlabeled Reinforcement Learning Distillation for On-Premise
Small Models. In: arXiv. [<a href=https://arxiv.org/pdf/2601.20687>arXiv</a>]</p><p>Zhiqiang Kou, Junyang Chen, <b>Xin-Qiang Cai</b>, Ming-Kun Xie, Biao Liu, Changwei Wang, Lei Feng, Yuheng Jia,
Gang Niu, Masashi Sugiyama, Xin Geng. Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label
Perspective. In: arXiv. [<a href=https://arxiv.org/pdf/2510.15007>arXiv</a>]</p><p><b>Xin-Qiang Cai</b>, Wei Wang, Feng Liu, Tongliang Liu, Gang Niu, Masashi Sugiyama. Reinforcement Learning
with Verifiable yet Noisy Rewards under Imperfect Verifiers. In: arXiv. [<a href=https://arxiv.org/pdf/2510.00915>arXiv</a>]</p><p>Jiansong Wan, Chengming Zhou, Jinkua Liu, Xiangge Huang, Xiaoyu Chen, Xiaohan Yi, Qisen Yang, Baiting Zhu,
<b>Xin-Qiang Cai</b>, Lixing Liu, Rushuai Yang, Chuheng Zhang, Sherif Abdelfattah, Hayong Shin, Pushi Zhang, Li
Zhao, Jiang Bian. PIG-Nav: Key Insights for Pretrained Image Goal Navigation Models. In: arXiv. [<a href=https://arxiv.org/pdf/2507.17220>arXiv</a>]</p><p>Zelei Cheng*, <b>Xin-Qiang Cai*</b>, Yuting Tang, Pushi Zhang, Boming Yang, Masashi Sugiyama, Xingyu Xing.
UC-MOA: Utility-Conditioned Multi-Objective Alignment for Distributional Pareto-Optimality. In: arXiv. [<a href=https://arxiv.org/pdf/2503.10669>arXiv</a>]</p><h2>Publications (* denotes equal contributions)</h2><p>Soichiro Nishimori, <b>Xin-Qiang Cai</b>, Johannes Ackermann, Masashi Sugiyama. Leveraging Domain-Unlabeled
Data in Offline Reinforcement Learning across Two Domains. <b>Proceedings of the second Reinforcement Learning
Conference (RLC'25)</b>, Montr√©al, QC, Canada, Aug. 16-19, 2025. [<a href=https://arxiv.org/abs/2404.07465>arXiv</a>]</p><p>Jing-Cheng Pang, Nan Tang, Kaiyuan Li, Yuting Tang, <b>Xin-Qiang Cai</b>, Zhen-Yu Zhang, Gang Niu, Masashi
Sugiyama, Yang Yu. Learning View-invariant World Models for Visual Robotic Manipulation. In: <b>Proceedings of
the Thirteenth International Conference on Learning Representations (ICLR'25)</b>, Singapore, Apr. 24-28,
2025.</p><p>Zelei Cheng, Xian Wu, Jiahao Yu, Shuo Han, <b>Xin-Qiang Cai</b>, Xinyu Xing. Soft-Label Integration for Robust
Toxicity Classification. In: <b>Proceedings of the Thirty-eighth Conference on Neural Information Processing
Systems (NeurIPS'24)</b>, Vancouver, Canada, Dec. 10‚Äì15, 2024. [<a href=https://arxiv.org/abs/2410.14894>arXiv</a>] [<a href=https://github.com/chengzelei/crowdsource_toxicity_classification>code</a>] [<a href=./files/softlabel-neurips24.pdf>paper</a>]</p><p>Yuting Tang*, <b>Xin-Qiang Cai*</b>, Yao-Xiang Ding, Qiyu Wu, Guoqing Liu, Masashi Sugiyama. Reinforcement
Learning from Bagged Reward. In: <b>Proceedings of the 41st International Conference on Machine Learning
(ICML'24), ARLET workshop</b>, Vienna, Austria, Jul. 21‚Äì27, 2024. [<a href=https://arxiv.org/abs/2402.03771>arXiv</a>]</p><p>Xingyu Song, Zhan Li, Shi Chen, <b>Xin-Qiang Cai</b>, Kazuyuki Demachi. An Animation-based Augmentation
Approach for Action Recognition from Discontinuous Video. In: <b>Proceedings of the 27th European Conference on
Artificial Intelligence (ECAI'24)</b>, Santiago de Compostela, Spain, Oct. 19‚Äì24, 2024. [<a href=https://arxiv.org/abs/2404.06741>arXiv</a>]</p><p>Kaiyan Zhao, Qiyu Wu, <b>Xin-Qiang Cai</b>, Yoshimasa Tsuruoka. Leveraging Multi-lingual Positive Instances in
Contrastive Learning to Improve Sentence Embedding. In: <b>Proceedings of the 8th Conference of the European
Chapter of the Association for Computational Linguistics (EACL'24)</b>, Malta, Mar. 17‚Äì22, 2024. [<a href=https://arxiv.org/abs/2309.08929>arXiv</a>]</p><p>Pushi Zhang*, Baiting Zhu*, <b>Xin-Qiang Cai*</b>, Li Zhao, Masashi Sugiyama, Jiang Bian. IG-Net: Image-Goal
Network for Offline Visual Navigation on A Large-Scale Game Map. In: <b>Proceedings of the Thirty-seventh
Conference on Neural Information Processing Systems (NeurIPS'23)</b>, <a href=https://www.robot-learning.ml/2023/>6th Robot Learning Workshop</a>, New Orleans, US, Dec. 10‚Äì16, 2023.
[<a href=./files/IG-neurips23.pdf>paper</a>] [<a href="https://openreview.net/forum?id=SjNlIHY8db">openreview</a>]</p><p><b>Xin-Qiang Cai</b>, Yu-Jie Zhang, Chao-Kai Chiang, Masashi Sugiyama. Imitation Learning from Vague Feedback.
In: <b>Proceedings of the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS'23)</b>,
New Orleans, US, Dec. 10‚Äì16, 2023. [<a href=./files/VPIL-neurips23.pdf>paper</a>] [<a href=./bib/2023-NeurIPS-VPIL.html>bibtex</a>]</p><p><b>Xin-Qiang Cai</b>, Pushi Zhang, Li Zhao, Jiang Bian, Masashi Sugiyama, Ashley Juan Llorens. Distributional
Pareto-Optimal Multi-Objective Reinforcement Learning. In: <b>Proceedings of the Thirty-seventh Conference on
Neural Information Processing Systems (NeurIPS'23)</b>, New Orleans, US, Dec. 10‚Äì16, 2023. [<a href=./files/DPMORL-neurips23.pdf>paper</a>] [<a href=./bib/2023-NeurIPS-DPMORL.html>bibtex</a>]</p><p><b>Xin-Qiang Cai</b>, Yao-Xiang Ding, Zi-Xuan Chen, Yuan Jiang, Masashi Sugiyama, Zhi-Hua Zhou. Seeing
Differently, Acting Similarly: Heterogeneously Observable Imitation Learning. In: <b>Proceedings of the Eleventh
International Conference on Learning Representations (ICLR'23) (spotlight)</b>, Kigali, Rwanda, May 1‚Äì5, 2023.
[<a href="https://openreview.net/forum?id=3ULaIHxn9u7">openreview</a>] [<a href=./files/HOIL-iclr23.pdf>paper</a>] [<a href=./bib/2023-ICLR-HOIL.html>bibtex</a>]</p><p>Zi-Xuan Chen*, <b>Xin-Qiang Cai*</b>, Yuan Jiang, Zhi-Hua Zhou. Anomaly Guided Policy Learning from Imperfect
Demonstrations. In: <b>Proceedings of the 21st International Conference on Autonomous Agents and Multi-Agent
Systems (AAMAS'22) (oral)</b>, Auckland, New Zealand, May 9‚Äì13, 2022. Page: 244‚Äì252. [<a href=./files/AGPO-aamas22.pdf>paper</a>] [<a href=./bib/2022-AAMAS-AGPO.html>bibtex</a>]</p><h2>Patent</h2><ul><li>‰∏ÄÁßçÊëÑÂÉèÂô®ÊùêËÆ∞ÂΩïÁöÑËßÜÈ¢ëÂõæÂÉèÊï∞ÊçÆÁöÑÈ´òÁª¥Ê®°‰ªøÂ≠¶‰π†ÊñπÊ≥ï. Patent No. 202011450396.1, 2020.</li></ul></section><section id=services class=section><h2>Service</h2><h3>Conference</h3><p>ECC, ICLR, NeurIPS, ICML, IJCAI, SDM, UAI, CCML, ECAI, CIKM</p><h3>Journal</h3><ul><li><a href=https://link.springer.com/journal/10994 target=_blank>Machine Learning (MLJ)</a></li><li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385" target=_blank>IEEE Transactions
on Neural Networks and Learning Systems (TNNLS)</a></li></ul></section><section id=awards class=section><h2>Awards & Honors</h2><ul><li>Star of Tomorrow Award. Microsoft Research Asia (MSRA). 2024</li><li><a href=https://www.jsps.go.jp/ target=_blank>Japan Society for the Promotion of Science (JSPS, Êó•Êú¨Â≠¶Ë°ìÊåØÂÖ¥‰ºö)
DC2 Fellowship</a>. 2023</li><li>MSRA Collaborative Research Program Fellowship (D-CORE 2022). 2022</li><li><a href=https://spring-gx-appl.adm.s.u-tokyo.ac.jp/en/ target=_blank>SPRING GX Fellowship</a>. 2021</li><li>Excellent Graduate of Nanjing University. 2021</li><li>AAMAS 2021 Attendance Scholarship. 2020</li><li>Excellent Graduate Student of Nanjing University. 2019</li><li>YeePay Scholarship of Nanjing University, Second Prize. 2019</li><li><a href=http://icdm2019.bigke.org/ target=_blank>ICDM Student Travel Award</a>. 2019</li><li><a href=https://grawww.nju.edu.cn/9a/a6/c905a301734/page.psp target=_blank>Yingcai Scholarship of
Nanjing University</a>, Second Prize. 2018</li><li>Nanjing University Academic Scholarship, First Prize. 2018&amp;2019&amp;2020</li><li>ZhongAn Hackathon Contest, AI scenario, First Prize. 2018</li><li>Excellent Graduate of Northwestern Polytechnical University. 2018</li><li>China Collegiate Computer Contest, First Prize. 2017</li><li>The ACM-ICPC Asia Regional Contest, Qingdao Site 2017, Silver Medal. 2017</li><li>The ACM-ICPC Asia Regional Contest, Xinjiang Site 2017, Bronze Medal. 2017</li><li>Interdisciplinary Contest in Modeling, Honorable Mention. 2017</li><li>China Collegiate Computer Contest, First Prize. 2017</li><li>Interdisciplinary Contest in Modeling, Honorable Mention. 2016</li><li>Contemporary Undergraduate Mathematical Contest in Modeling, Third Prize. 2016</li><li>China Collegiate Programming Contest, Hangzhou Site 2016, Silver Medal. 2016</li><li>China Collegiate Computer Contest, First Prize. 2016</li><li>The ACM-ICPC Asia Regional Contest, Xi‚Äôan Site 2016, Bronze Medal. 2016</li><li>The ACM-ICPC Asia Regional Contest, Shanghai Site 2016, Bronze Medal. 2016</li><li>The ACM-ICPC Asia Regional Contest, China-Final, Bronze Medal. 2015</li><li>Contemporary Undergraduate Mathematical Contest in Modeling, Second Prize. 2015</li><li>The ACM-ICPC Asia Regional Contest, Shaanxi Provincial Contest, Silver Medal. 2015</li><li>National Scholarship. 2015‚Äì2016</li><li>National Scholarship. 2014‚Äì2015</li></ul></section><section id=correspondence class=section><h2>Correspondence</h2><p>Email: xinqiang.cai@riken.jp, jkrsndivide@gmail.com</p></section></main><footer><p>¬© 2025 Xin-Qiang Cai</p></footer><script>(()=>{const d=document.getElementById("interactive-bg"),e=d.getContext("2d"),o=Math.min(window.devicePixelRatio||1,2);let n=0,s=0,b=0;function C(){const e=getComputedStyle(document.documentElement);return{primary:(e.getPropertyValue("--primary-rgb")||"0,95,115").trim(),accent:(e.getPropertyValue("--accent-rgb")||"10,147,150").trim(),ink:(e.getPropertyValue("--ink-rgb")||"0,18,25").trim(),bg:(e.getPropertyValue("--canvas-bg-rgb")||"245,247,248").trim()}}let r=C();const E=110,z=140,i=[],m=["argmax_œÄ  E[‚àë Œ≥^t r_t]","min_Œ∏  E[(R ‚àí f_Œ∏)^2]","‚àá¬∑(œÉ‚àáV) = 0","H(s,a) = ‚àí‚àë p log p","Q^œÄ(s,a) = r + Œ≥ E[Q^œÄ(s‚Ä≤,a‚Ä≤)]","KL(p‚Äñq) = ‚àë p log(p/q)"].map(e=>({text:e,x:0,y:0,vx:0,vy:0,a:Math.random()*.3+.05}));function j(){n=Math.floor(innerWidth*o),s=Math.floor(innerHeight*o),d.width=n,d.height=s,d.style.width=innerWidth+"px",d.style.height=innerHeight+"px"}function x(){i.length=0;for(let e=0;e<E;e++)i.push({x:Math.random()*n,y:Math.random()*s,vx:(Math.random()-.5)*.3,vy:(Math.random()-.5)*.3,pulse:Math.random()*Math.PI*2});m.forEach((e,t)=>{e.x=(t+1)/(m.length+1)*n,e.y=(.25+.5*Math.random())*s,e.vx=(Math.random()-.5)*.15,e.vy=(Math.random()-.5)*.15})}const a={x:-1e9,y:-1e9};window.addEventListener("mousemove",e=>{a.x=e.clientX*o,a.y=e.clientY*o}),window.addEventListener("mouseleave",()=>{a.x=-1e9,a.y=-1e9});function O(e,t,n){const s=9e-4,o=n*3e-4,i=Math.sin(t*s+o)*.25+Math.sin((e+t)*s*.6)*.15,a=Math.cos(e*s*1.1+o)*.25+Math.sin((e-t)*s*.5)*.1;return{x:i,y:a}}function w(t){b=t||0,e.clearRect(0,0,n,s),e.globalCompositeOperation="source-over",e.fillStyle="rgb("+r.bg+")",e.fillRect(0,0,n,s);const c=e.createLinearGradient(0,0,n,s);c.addColorStop(0,"rgba("+r.primary+",0.12)"),c.addColorStop(1,"rgba("+r.accent+",0.08)"),e.fillStyle=c,e.fillRect(0,0,n,s);for(let r=0;r<i.length;r++){const e=i[r],c=O(e.x,e.y,b),l=e.x-a.x,d=e.y-a.y,t=Math.hypot(l,d),u=t<160*o?(160*o-t)/(160*o):0;e.vx+=c.x*.6-l/(t+1)*u*.4,e.vy+=c.y*.6-d/(t+1)*u*.4,e.x+=e.vx,e.y+=e.vy,e.vx*=.97,e.vy*=.97,e.x<-20&&(e.x=n+20),e.x>n+20&&(e.x=-20),e.y<-20&&(e.y=s+20),e.y>s+20&&(e.y=-20),e.pulse+=.02}e.globalCompositeOperation="lighter",e.fillStyle="rgba("+r.primary+",0.75)",e.beginPath();for(let n=0;n<i.length;n++){const t=i[n],s=1.1+Math.sin(t.pulse)*.9;e.moveTo(t.x+s,t.y),e.arc(t.x,t.y,s,0,Math.PI*2)}e.fill();const l=140*o,d=l*l;e.lineWidth=1*o;for(let t=0;t<i.length;t++){const n=i[t];for(let o=t+1;o<i.length;o++){const s=i[o],a=n.x-s.x,c=n.y-s.y,u=a*a+c*c;if(u<d){const o=Math.sqrt(u),t=1-o/l;t>.05&&(e.beginPath(),e.strokeStyle="rgba("+r.accent+","+(.28*t+.06)+")",e.moveTo(n.x,n.y),e.lineTo(s.x,s.y),e.stroke())}}}e.globalCompositeOperation="source-over",e.font=14*o+"px ui-monospace, Menlo, Consolas, Monaco, monospace",e.fillStyle="rgba("+r.ink+",0.12)",m.forEach(t=>{const o=O(t.x,t.y,b);t.vx+=o.x*t.a*.5,t.vy+=o.y*t.a*.5,t.x+=t.vx,t.y+=t.vy,t.vx*=.985,t.vy*=.985,t.x<-200&&(t.x=n+200),t.x>n+200&&(t.x=-200),t.y<-50&&(t.y=s+50),t.y>s+50&&(t.y=-50),e.fillText(t.text,t.x,t.y)}),requestAnimationFrame(w)}let _;function F(){j(),x(),w(0)}window.addEventListener("resize",()=>{clearTimeout(_),_=setTimeout(()=>{j(),x()},200)}),F();const g=!1,M=document.querySelector("main");let t=null,u=()=>{},v=()=>{};if(g){t=document.createElement("div"),t.id="data-widget",t.innerHTML=`<p id="widget-status">Connecting to your world...</p><p class="blessing-message"></p>`,document.body.appendChild(t);let n=150,e=150;const o=.08;let s={left:0,right:0};u=function(){const e=M.getBoundingClientRect(),i=e.left+window.scrollX,n=e.right+window.scrollX;s.left=i,s.right=n;const o=n+20,a=o+280<window.scrollX+window.innerWidth;a?(t.classList.remove("is-docked"),t.style.left=o+"px"):t.classList.add("is-docked")},v=function(){e+=(n-e)*o,t.classList.contains("is-docked")||(t.style.top=e+"px"),requestAnimationFrame(v)},window.addEventListener("scroll",()=>{n=window.scrollY+150}),window.addEventListener("resize",u),u(),v()}function S(e,t){return e<0&&(t=(t+6)%12),t>=2&&t<=4?"spring":t>=5&&t<=7?"summer":t>=8&&t<=10?"autumn":"winter"}function A(e){const t=["N","NNE","NE","ENE","E","ESE","SE","SSE","S","SSW","SW","WSW","W","WNW","NW","NNW"];return t[Math.round(e/22.5)%16]}async function k(){try{const c=await fetch("https://ipapi.co/json/");if(!c.ok)throw new Error("Geolocation failed");const y=await c.json(),{latitude:r,longitude:f,city:j,country_name:b}=y,h=S(r,(new Date).getMonth()),v=`https://api.open-meteo.com/v1/forecast?latitude=${r}&longitude=${f}&current=wind_speed_10m,wind_direction_10m`,e=await fetch(v);if(!e.ok)throw new Error("Weather data failed");const p=await e.json(),{wind_speed_10m:m,wind_direction_10m:d}=p.current,l=(d-90+180)*(Math.PI/180),i=m/50*200*o;if(a.x=n/2+Math.cos(l)*i,a.y=s/2+Math.sin(l)*i,g&&t){const e=document.getElementById("widget-status");if(e){const t=h[0].toUpperCase()+h.slice(1);e.innerHTML=`Welcome from <strong>${j}, ${b}</strong>.<br/>The current season is <strong>${t}</strong>, and the wind is <strong>${m.toFixed(1)} km/h</strong> from the <strong>${A(d)}</strong>.`}const n=t.querySelector(".blessing-message");n&&(n.innerHTML="The neural graph gently drifts with your local breeze ‚Äî wishing you clarity and happy discoveries today."),t.classList.add("loaded"),u()}}catch{if(g&&t){const e=document.getElementById("widget-status");e&&(e.innerHTML="Could not connect to your world, but the math still flows.");const n=t.querySelector(".blessing-message");n&&(n.innerHTML="Wishing you a wonderful day, wherever you are. ‚ú®"),t.classList.add("loaded"),u()}}}k();const f="theme",l=document.documentElement,c=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)");function h(e){e==="dark"?l.setAttribute("data-theme","dark"):e==="light"?l.setAttribute("data-theme","light"):l.removeAttribute("data-theme"),r=C();const t=document.getElementById("theme-toggle"),n=l.getAttribute("data-theme")==="dark"||!l.hasAttribute("data-theme")&&c&&c.matches;t&&(t.textContent=n?"‚òÄÔ∏è":"üåô")}function y(){const t=localStorage.getItem(f);h(t==="light"||t==="dark"?t:null),c&&c.addEventListener&&c.addEventListener("change",()=>{localStorage.getItem(f)||h(null)});const e=document.getElementById("theme-toggle");e&&!e._bound&&(e.addEventListener("click",()=>{const t=l.getAttribute("data-theme")||(c&&c.matches?"dark":"light"),e=t==="dark"?"light":"dark";localStorage.setItem(f,e),h(e)}),e._bound=!0)}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",y):y();const p=Array.from(document.querySelectorAll(".nav-buttons a.button")),T=p.map(e=>document.getElementById(e.dataset.target||e.getAttribute("href").slice(1))).filter(Boolean);if("IntersectionObserver"in window){const e=new IntersectionObserver(e=>{e.forEach(e=>{const n=e.target.getAttribute("id"),t=p.find(e=>(e.dataset.target||e.getAttribute("href").slice(1))===n);if(!t)return;e.isIntersecting&&(p.forEach(e=>e.classList.remove("active")),t.classList.add("active"))})},{root:null,rootMargin:"0px 0px -70% 0px",threshold:.2});T.forEach(t=>e.observe(t))}})()</script></body></html>