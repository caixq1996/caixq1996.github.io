<!doctype html>
<html lang=en>
<head>
<meta charset=UTF-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<title>Publications | Xin-Qiang Cai</title>
<meta name=description content="Complete preprints and publications by Xin-Qiang Cai.">
<link rel=icon href=/icons/favicon.ico sizes="16x16 32x32 48x48">
<link rel=preconnect href=https://fonts.googleapis.com>
<link rel=preconnect href=https://fonts.gstatic.com crossorigin>
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;500;600&family=IBM+Plex+Sans:wght@400;500;600;700&display=swap" rel=stylesheet>
<style>
  :root {
    --bg: #f3f7fc;
    --bg-soft: #e7eff8;
    --panel: rgba(255, 255, 255, 0.82);
    --text: #0f172a;
    --muted: #4b5563;
    --line: rgba(15, 23, 42, 0.14);
    --brand: #0a4f85;
    --chip: #e2eefb;
    --shadow: 0 18px 45px -22px rgba(15, 23, 42, 0.45);
    --canvas-bg-rgb: 243, 247, 252;
    --primary-rgb: 10, 79, 133;
    --accent-rgb: 21, 112, 184;
    --ink-rgb: 15, 23, 42;
  }

  :root[data-theme=dark] {
    --bg: #0d1423;
    --bg-soft: #121d2f;
    --panel: rgba(17, 28, 45, 0.84);
    --text: #e5edf7;
    --muted: #9cb0ca;
    --line: rgba(229, 237, 247, 0.18);
    --brand: #7ab8ff;
    --chip: #162741;
    --shadow: 0 18px 45px -20px rgba(0, 0, 0, 0.7);
    --canvas-bg-rgb: 13, 20, 35;
    --primary-rgb: 122, 184, 255;
    --accent-rgb: 163, 205, 255;
    --ink-rgb: 229, 237, 247;
  }

  @media (prefers-color-scheme: dark) {
    :root:not([data-theme=light]) {
      --bg: #0d1423;
      --bg-soft: #121d2f;
      --panel: rgba(17, 28, 45, 0.84);
      --text: #e5edf7;
      --muted: #9cb0ca;
      --line: rgba(229, 237, 247, 0.18);
      --brand: #7ab8ff;
      --chip: #162741;
      --shadow: 0 18px 45px -20px rgba(0, 0, 0, 0.7);
      --canvas-bg-rgb: 13, 20, 35;
      --primary-rgb: 122, 184, 255;
      --accent-rgb: 163, 205, 255;
      --ink-rgb: 229, 237, 247;
    }
  }

  * {
    box-sizing: border-box;
  }

  body {
    margin: 0;
    min-height: 100vh;
    color: var(--text);
    background-image:
      radial-gradient(circle at 15% 15%, rgba(21, 112, 184, 0.18), transparent 34%),
      radial-gradient(circle at 85% 10%, rgba(10, 79, 133, 0.16), transparent 30%),
      linear-gradient(to bottom, var(--bg-soft), var(--bg));
    font-family: ibm plex sans, segoe ui, sans-serif;
    line-height: 1.65;
    position: relative;
    overflow-x: hidden;
  }

  body::before {
    content: "";
    position: fixed;
    inset: 0;
    pointer-events: none;
    opacity: 0.25;
    z-index: 1;
    background-image:
      linear-gradient(to right, var(--line) 1px, transparent 1px),
      linear-gradient(to bottom, var(--line) 1px, transparent 1px);
    background-size: 34px 34px;
    mask-image: linear-gradient(to bottom, rgba(0, 0, 0, 0.35), transparent 70%);
  }

  #interactive-bg {
    position: fixed;
    inset: 0;
    z-index: 0;
    pointer-events: none;
  }

  .wrap {
    width: min(1100px, calc(100% - 2rem));
    margin: 1.1rem auto 2rem;
    position: relative;
    z-index: 2;
  }

  .top {
    display: flex;
    justify-content: space-between;
    align-items: center;
    gap: 1rem;
    background: var(--panel);
    border: 1px solid var(--line);
    border-radius: 14px;
    padding: .72rem .9rem;
    box-shadow: var(--shadow);
    margin-bottom: 1rem;
  }

  .top-actions {
    display: flex;
    align-items: center;
    gap: .5rem;
    flex-wrap: wrap;
    justify-content: flex-end;
  }

  .brand {
    font-family: ibm plex mono, monospace;
    font-size: .86rem;
    letter-spacing: .08em;
    text-transform: uppercase;
    color: var(--brand);
  }

  .nav-link,
  .theme-toggle {
    border: 1px solid var(--line);
    border-radius: 999px;
    padding: .4rem .7rem;
    font-size: .82rem;
    font-family: ibm plex mono, monospace;
    color: var(--text);
    text-decoration: none;
    background: var(--chip);
  }

  .theme-toggle {
    cursor: pointer;
  }

  .panel {
    background: var(--panel);
    border: 1px solid var(--line);
    border-radius: 16px;
    box-shadow: var(--shadow);
    padding: 1.25rem;
  }

  h1 {
    margin: 0 0 .25rem;
    font-size: clamp(1.5rem, 3vw, 2.2rem);
    letter-spacing: -.02em;
  }

  .desc {
    margin: 0 0 1.1rem;
    color: var(--muted);
    font-size: .95rem;
  }

  .pub-content h2 {
    margin: 1.45rem 0 .8rem;
    font-size: 1.25rem;
    border-left: 4px solid var(--brand);
    padding-left: .6rem;
  }

  .pub-content p {
    margin: 0 0 .95rem;
    color: var(--muted);
  }

  .pub-content a {
    color: var(--brand);
    text-decoration: underline;
    text-underline-offset: 2px;
  }
</style>
</head>
<body>
<canvas id=interactive-bg aria-hidden=true></canvas>
<main class=wrap>
<header class=top>
<div class=brand>Xin-Qiang Cai / Publications</div>
<div class=top-actions>
<a class=nav-link href=../index.html>Back to Home</a>
<button id=theme-toggle class=theme-toggle type=button aria-label="Toggle theme">Theme</button>
</div>
</header>
<article class=panel>
<h1>Publications</h1>
<p class=desc>Complete preprints and publications list.</p>
<div class=pub-content>
<h2>Preprints (* denotes equal contributions)</h2>
<p>
<b>Xin-Qiang Cai</b>, Masashi Sugiyama. VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via
Confidence-Guided Variance Reduction. In: arXiv. [<a href=https://arxiv.org/pdf/2602.12579>arXiv</a>]</p>
<p>Zhiqiang Kou*, Junyang Chen*, <b>Xin-Qiang Cai</b>, Xiaobo Xia, Ming-Kun Xie, Dong-Dong Wu, Biao Liu, Yuheng
Jia,
Xin Geng, Masashi Sugiyama, Tat-Seng Chua. Positive-Unlabeled Reinforcement Learning Distillation for On-Premise
Small Models. In: arXiv. [<a href=https://arxiv.org/pdf/2601.20687>arXiv</a>]</p>
<p>Zhiqiang Kou, Junyang Chen, <b>Xin-Qiang Cai</b>, Ming-Kun Xie, Biao Liu, Changwei Wang, Lei Feng, Yuheng Jia,
Gang Niu, Masashi Sugiyama, Xin Geng. Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label
Perspective. In: arXiv. [<a href=https://arxiv.org/pdf/2510.15007>arXiv</a>]</p>
<p>
<b>Xin-Qiang Cai</b>, Wei Wang, Feng Liu, Tongliang Liu, Gang Niu, Masashi Sugiyama. Reinforcement Learning
with Verifiable yet Noisy Rewards under Imperfect Verifiers. In: arXiv. [<a href=https://arxiv.org/pdf/2510.00915>arXiv</a>]</p>
<p>Jiansong Wan, Chengming Zhou, Jinkua Liu, Xiangge Huang, Xiaoyu Chen, Xiaohan Yi, Qisen Yang, Baiting Zhu,
<b>Xin-Qiang Cai</b>, Lixing Liu, Rushuai Yang, Chuheng Zhang, Sherif Abdelfattah, Hayong Shin, Pushi Zhang, Li
Zhao, Jiang Bian. PIG-Nav: Key Insights for Pretrained Image Goal Navigation Models. In: arXiv. [<a href=https://arxiv.org/pdf/2507.17220>arXiv</a>]</p>
<p>Zelei Cheng*, <b>Xin-Qiang Cai*</b>, Yuting Tang, Pushi Zhang, Boming Yang, Masashi Sugiyama, Xingyu Xing.
UC-MOA: Utility-Conditioned Multi-Objective Alignment for Distributional Pareto-Optimality. In: arXiv. [<a href=https://arxiv.org/pdf/2503.10669>arXiv</a>]</p>
<h2>Publications (* denotes equal contributions)</h2>
<p>Soichiro Nishimori, <b>Xin-Qiang Cai</b>, Johannes Ackermann, Masashi Sugiyama. Leveraging Domain-Unlabeled
Data in Offline Reinforcement Learning across Two Domains. <b>Proceedings of the second Reinforcement Learning
Conference (RLC'25)</b>, Montréal, QC, Canada, Aug. 16-19, 2025. [<a href=https://arxiv.org/abs/2404.07465>arXiv</a>]</p>
<p>Jing-Cheng Pang, Nan Tang, Kaiyuan Li, Yuting Tang, <b>Xin-Qiang Cai</b>, Zhen-Yu Zhang, Gang Niu, Masashi
Sugiyama, Yang Yu. Learning View-invariant World Models for Visual Robotic Manipulation. In: <b>Proceedings of
the Thirteenth International Conference on Learning Representations (ICLR'25)</b>, Singapore, Apr. 24-28,
2025.</p>
<p>Zelei Cheng, Xian Wu, Jiahao Yu, Shuo Han, <b>Xin-Qiang Cai</b>, Xinyu Xing. Soft-Label Integration for Robust
Toxicity Classification. In: <b>Proceedings of the Thirty-eighth Conference on Neural Information Processing
Systems (NeurIPS'24)</b>, Vancouver, Canada, Dec. 10–15, 2024. [<a href=https://arxiv.org/abs/2410.14894>arXiv</a>] [<a href=https://github.com/chengzelei/crowdsource_toxicity_classification>code</a>] [<a href=/files/softlabel-neurips24.pdf>paper</a>]</p>
<p>Yuting Tang*, <b>Xin-Qiang Cai*</b>, Yao-Xiang Ding, Qiyu Wu, Guoqing Liu, Masashi Sugiyama. Reinforcement
Learning from Bagged Reward. In: <b>Proceedings of the 41st International Conference on Machine Learning
(ICML'24), ARLET workshop</b>, Vienna, Austria, Jul. 21–27, 2024. [<a href=https://arxiv.org/abs/2402.03771>arXiv</a>]</p>
<p>Xingyu Song, Zhan Li, Shi Chen, <b>Xin-Qiang Cai</b>, Kazuyuki Demachi. An Animation-based Augmentation
Approach for Action Recognition from Discontinuous Video. In: <b>Proceedings of the 27th European Conference on
Artificial Intelligence (ECAI'24)</b>, Santiago de Compostela, Spain, Oct. 19–24, 2024. [<a href=https://arxiv.org/abs/2404.06741>arXiv</a>]</p>
<p>Kaiyan Zhao, Qiyu Wu, <b>Xin-Qiang Cai</b>, Yoshimasa Tsuruoka. Leveraging Multi-lingual Positive Instances in
Contrastive Learning to Improve Sentence Embedding. In: <b>Proceedings of the 8th Conference of the European
Chapter of the Association for Computational Linguistics (EACL'24)</b>, Malta, Mar. 17–22, 2024. [<a href=https://arxiv.org/abs/2309.08929>arXiv</a>]</p>
<p>Pushi Zhang*, Baiting Zhu*, <b>Xin-Qiang Cai*</b>, Li Zhao, Masashi Sugiyama, Jiang Bian. IG-Net: Image-Goal
Network for Offline Visual Navigation on A Large-Scale Game Map. In: <b>Proceedings of the Thirty-seventh
Conference on Neural Information Processing Systems (NeurIPS'23)</b>, <a href=https://www.robot-learning.ml/2023/>6th Robot Learning Workshop</a>, New Orleans, US, Dec. 10–16, 2023.
[<a href=/files/IG-neurips23.pdf>paper</a>] [<a href="https://openreview.net/forum?id=SjNlIHY8db">openreview</a>]</p>
<p>
<b>Xin-Qiang Cai</b>, Yu-Jie Zhang, Chao-Kai Chiang, Masashi Sugiyama. Imitation Learning from Vague Feedback.
In: <b>Proceedings of the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS'23)</b>,
New Orleans, US, Dec. 10–16, 2023. [<a href=/files/VPIL-neurips23.pdf>paper</a>] [<a href=/bib/2023-NeurIPS-VPIL.html>bibtex</a>]</p>
<p>
<b>Xin-Qiang Cai</b>, Pushi Zhang, Li Zhao, Jiang Bian, Masashi Sugiyama, Ashley Juan Llorens. Distributional
Pareto-Optimal Multi-Objective Reinforcement Learning. In: <b>Proceedings of the Thirty-seventh Conference on
Neural Information Processing Systems (NeurIPS'23)</b>, New Orleans, US, Dec. 10–16, 2023. [<a href=/files/DPMORL-neurips23.pdf>paper</a>] [<a href=/bib/2023-NeurIPS-DPMORL.html>bibtex</a>]</p>
<p>
<b>Xin-Qiang Cai</b>, Yao-Xiang Ding, Zi-Xuan Chen, Yuan Jiang, Masashi Sugiyama, Zhi-Hua Zhou. Seeing
Differently, Acting Similarly: Heterogeneously Observable Imitation Learning. In: <b>Proceedings of the Eleventh
International Conference on Learning Representations (ICLR'23) (spotlight)</b>, Kigali, Rwanda, May 1–5, 2023.
[<a href="https://openreview.net/forum?id=3ULaIHxn9u7">openreview</a>] [<a href=/files/HOIL-iclr23.pdf>paper</a>] [<a href=/bib/2023-ICLR-HOIL.html>bibtex</a>]</p>
<p>Zi-Xuan Chen*, <b>Xin-Qiang Cai*</b>, Yuan Jiang, Zhi-Hua Zhou. Anomaly Guided Policy Learning from Imperfect
Demonstrations. In: <b>Proceedings of the 21st International Conference on Autonomous Agents and Multi-Agent
Systems (AAMAS'22) (oral)</b>, Auckland, New Zealand, May 9–13, 2022. Page: 244–252. [<a href=/files/AGPO-aamas22.pdf>paper</a>] [<a href=/bib/2022-AAMAS-AGPO.html>bibtex</a>]</p>
<p><b>Xin-Qiang Cai</b>, Yao-Xiang Ding, Yuan Jiang, Zhi-Hua Zhou. Imitation Learning from Pixel-Level
Demonstrations by HashReward. In: <b>Proceedings of the 20th International Conference on Autonomous Agents and
Multi-Agent Systems (AAMAS'21) (oral)</b>, online, May 3–7, 2021. Page: 279–287. [<a href=http://www.lamda.nju.edu.cn/code_HashReward.ashx>code</a>] [<a href=/files/hashreward-aamas21.pdf>paper</a>] [<a href=/bib/2021-AAMAS-HashReward.html>bibtex</a>]</p>
<p><b>Xin-Qiang Cai</b>, Peng Zhao, Kai Ming Ting, Xin Mu, Yuan Jiang. Nearest Neighbor Ensembles: An Effective
Method for Difficult Problems in Streaming Classification with Emerging New Classes. In: <b>Proceedings of the
19th IEEE International Conference on Data Mining (ICDM'19)</b>, Beijing, China, Nov. 8–11, 2019. Page:
970–975. [<a href=/files/SENNE_code.zip>code</a>] [<a href=/files/SENNE.pdf>paper</a>] [<a href=/bib/2019-ICDM-SENNE.html>bibtex</a>]</p>
<h2>Patent</h2>
<ul>
<li>一种摄像器材记录的视频图像数据的高维模仿学习方法. Patent No. 202011450396.1, 2020.</li>
</ul>
</div>
</article>
</main>
<script>
  (function () {
    const canvas = document.getElementById("interactive-bg");
    if (!canvas) return;
    const ctx = canvas.getContext("2d");
    const dpr = Math.min(window.devicePixelRatio || 1, 2);

    let w = 0;
    let h = 0;
    let t = 0;
    let rafId = null;
    const mouse = { x: -1e9, y: -1e9 };

    const nodeCount = 90;
    const linkRadius = 130;
    const nodes = [];
    const equations = [
      "argmax_pi E[sum gamma^t r_t]",
      "Q_pi(s,a) = r + gamma E[Q_pi(s',a')]",
      "min_theta E[(R - f_theta)^2]",
      "KL(p||q) = sum p log(p/q)",
      "H(s,a) = -sum p log p",
      "div(sigma grad V)=0"
    ].map((text) => ({ text, x: 0, y: 0, vx: 0, vy: 0, alpha: Math.random() * 0.3 + 0.05 }));

    function readColors() {
      const cs = getComputedStyle(document.documentElement);
      return {
        bg: (cs.getPropertyValue("--canvas-bg-rgb") || "243,247,252").trim(),
        primary: (cs.getPropertyValue("--primary-rgb") || "10,79,133").trim(),
        accent: (cs.getPropertyValue("--accent-rgb") || "21,112,184").trim(),
        ink: (cs.getPropertyValue("--ink-rgb") || "15,23,42").trim()
      };
    }

    let colors = readColors();

    function resize() {
      w = Math.floor(window.innerWidth * dpr);
      h = Math.floor(window.innerHeight * dpr);
      canvas.width = w;
      canvas.height = h;
      canvas.style.width = window.innerWidth + "px";
      canvas.style.height = window.innerHeight + "px";
    }

    function init() {
      nodes.length = 0;
      for (let i = 0; i < nodeCount; i += 1) {
        nodes.push({
          x: Math.random() * w,
          y: Math.random() * h,
          vx: (Math.random() - 0.5) * 0.32,
          vy: (Math.random() - 0.5) * 0.32,
          pulse: Math.random() * Math.PI * 2
        });
      }

      equations.forEach((eq, idx) => {
        eq.x = ((idx + 1) / (equations.length + 1)) * w;
        eq.y = (0.2 + Math.random() * 0.6) * h;
        eq.vx = (Math.random() - 0.5) * 0.14;
        eq.vy = (Math.random() - 0.5) * 0.14;
      });
    }

    function flow(x, y, tt) {
      const s = 0.0009;
      const ttScaled = tt * 0.0003;
      const fx = Math.sin(y * s + ttScaled) * 0.24 + Math.sin((x + y) * s * 0.6) * 0.14;
      const fy = Math.cos(x * s * 1.1 + ttScaled) * 0.24 + Math.sin((x - y) * s * 0.5) * 0.1;
      return { x: fx, y: fy };
    }

    function draw(time) {
      t = time || 0;
      ctx.clearRect(0, 0, w, h);

      ctx.fillStyle = `rgb(${colors.bg})`;
      ctx.fillRect(0, 0, w, h);

      const grad = ctx.createLinearGradient(0, 0, w, h);
      grad.addColorStop(0, `rgba(${colors.primary},0.12)`);
      grad.addColorStop(1, `rgba(${colors.accent},0.08)`);
      ctx.fillStyle = grad;
      ctx.fillRect(0, 0, w, h);

      for (let i = 0; i < nodes.length; i += 1) {
        const n = nodes[i];
        const f = flow(n.x, n.y, t);
        const dx = n.x - mouse.x;
        const dy = n.y - mouse.y;
        const dist = Math.hypot(dx, dy);
        const repel = dist < 160 * dpr ? ((160 * dpr - dist) / (160 * dpr)) * 0.4 : 0;

        n.vx += f.x * 0.6 - (dx / (dist + 1)) * repel;
        n.vy += f.y * 0.6 - (dy / (dist + 1)) * repel;
        n.x += n.vx;
        n.y += n.vy;
        n.vx *= 0.97;
        n.vy *= 0.97;

        if (n.x < -20) n.x = w + 20;
        if (n.x > w + 20) n.x = -20;
        if (n.y < -20) n.y = h + 20;
        if (n.y > h + 20) n.y = -20;
        n.pulse += 0.02;
      }

      ctx.globalCompositeOperation = "lighter";
      ctx.fillStyle = `rgba(${colors.primary},0.72)`;
      ctx.beginPath();
      for (let i = 0; i < nodes.length; i += 1) {
        const n = nodes[i];
        const r = 1.05 + Math.sin(n.pulse) * 0.85;
        ctx.moveTo(n.x + r, n.y);
        ctx.arc(n.x, n.y, r, 0, Math.PI * 2);
      }
      ctx.fill();

      const radius = linkRadius * dpr;
      const radius2 = radius * radius;
      ctx.lineWidth = 1 * dpr;
      for (let i = 0; i < nodes.length; i += 1) {
        for (let j = i + 1; j < nodes.length; j += 1) {
          const a = nodes[i];
          const b = nodes[j];
          const dx = a.x - b.x;
          const dy = a.y - b.y;
          const d2 = dx * dx + dy * dy;
          if (d2 < radius2) {
            const d = Math.sqrt(d2);
            const alpha = 1 - d / radius;
            if (alpha > 0.05) {
              ctx.beginPath();
              ctx.strokeStyle = `rgba(${colors.accent},${0.28 * alpha + 0.06})`;
              ctx.moveTo(a.x, a.y);
              ctx.lineTo(b.x, b.y);
              ctx.stroke();
            }
          }
        }
      }

      ctx.globalCompositeOperation = "source-over";
      ctx.font = `${13 * dpr}px ui-monospace, Menlo, Consolas, Monaco, monospace`;
      ctx.fillStyle = `rgba(${colors.ink},0.14)`;
      equations.forEach((eq) => {
        const f = flow(eq.x, eq.y, t);
        eq.vx += f.x * eq.alpha * 0.55;
        eq.vy += f.y * eq.alpha * 0.55;
        eq.x += eq.vx;
        eq.y += eq.vy;
        eq.vx *= 0.985;
        eq.vy *= 0.985;

        if (eq.x < -240) eq.x = w + 240;
        if (eq.x > w + 240) eq.x = -240;
        if (eq.y < -60) eq.y = h + 60;
        if (eq.y > h + 60) eq.y = -60;

        ctx.fillText(eq.text, eq.x, eq.y);
      });

      rafId = requestAnimationFrame(draw);
    }

    window.addEventListener("mousemove", (event) => {
      mouse.x = event.clientX * dpr;
      mouse.y = event.clientY * dpr;
    });
    window.addEventListener("mouseleave", () => {
      mouse.x = -1e9;
      mouse.y = -1e9;
    });
    window.addEventListener("resize", () => {
      resize();
      init();
    });

    const observer = new MutationObserver(() => {
      colors = readColors();
    });
    observer.observe(document.documentElement, { attributes: true, attributeFilter: ["data-theme"] });

    resize();
    init();
    rafId = requestAnimationFrame(draw);

    window.addEventListener("beforeunload", () => {
      if (rafId) cancelAnimationFrame(rafId);
      observer.disconnect();
    });
  })();
</script>
<script>
  (function () {
    const root = document.documentElement;
    const key = "site-theme";
    const toggle = document.getElementById("theme-toggle");
    const prefersDark = window.matchMedia && window.matchMedia("(prefers-color-scheme: dark)").matches;

    const saved = localStorage.getItem(key);
    if (saved === "light" || saved === "dark") {
      root.setAttribute("data-theme", saved);
    } else if (prefersDark) {
      root.setAttribute("data-theme", "dark");
    }

    if (!toggle) return;
    toggle.addEventListener("click", function () {
      const current = root.getAttribute("data-theme") || (prefersDark ? "dark" : "light");
      const next = current === "dark" ? "light" : "dark";
      root.setAttribute("data-theme", next);
      localStorage.setItem(key, next);
    });
  })();
</script>
</body>
</html>
